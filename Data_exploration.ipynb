{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johann/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "NORMALIZATION = True\n",
    "NORM_ALL_DATA = False\n",
    "NORM_PHASE_1  = False\n",
    "NORM_PER_FILE = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not NORMALIZATION:\n",
    "    path = \"/home/johann/Desktop/Uni/Masterarbeit/Cycle_GAN/csv_export_files_alle_Daten/csv_export_files\" \n",
    "    csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    scaler = StandardScaler() \n",
    "    for f in csv_files:\n",
    "        df_temp = pd.read_csv(f, sep=\";\")\n",
    "        df_temp = utils.drop_cols(df_temp)\n",
    "        df_temp = df_temp.dropna()\n",
    "        df_temp = utils.remove_strings(df_temp)  \n",
    "        df = pd.concat([df, df_temp], axis=0)\n",
    "        \n",
    "    utils.get_data_overview(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get mean, standard deviation, min, max and median of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized per file\n",
      "Shape of DataFrame (6022044, 14)\n",
      "AoP: mean:  48.30847789525583 std:  15.153152923498263 min:  15.856160000083037 max:  140.38751000000047 median:  46.10740599997371\n",
      "VADcurrent: mean:  0.5541030138440085 std:  0.20167086814548843 min:  -0.8063268900004914 max:  5.092731500000809 median:  0.5115693499993199\n",
      "VadQ: mean:  2.1775348983652427 std:  0.9465230017230916 min:  -1.4067543999917689 max:  5.993453799997951 median:  2.1655909499982045\n",
      "LVP: mean:  27.25951742579371 std:  24.875284239815052 min:  -60.63108600000123 max:  166.53891999996267 median:  11.646741000042311\n",
      "LVtot_kalibriert: mean:  90.47925277948431 std:  42.87621222411684 min:  -33.8161546293486 max:  320.06734372721985 median:  88.45988649118226\n"
     ]
    }
   ],
   "source": [
    "if NORMALIZATION == True and NORM_PER_FILE == True:\n",
    "    path = \"/home/johann/Desktop/Uni/Masterarbeit/Cycle_GAN/csv_export_files_alle_Daten/csv_export_files\" \n",
    "    csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    scaler = StandardScaler() \n",
    "    for f in csv_files:\n",
    "        df_temp = pd.read_csv(f, sep=\";\")\n",
    "        df_temp = utils.drop_cols(df_temp)\n",
    "        df_temp = df_temp.dropna()\n",
    "        df_temp = utils.remove_strings(df_temp)  \n",
    "        df_temp = utils.subsample(df_temp, 10)\n",
    "        #df_temp = utils.normalize(df_temp, scaler, phase1 = True)\n",
    "        df = pd.concat([df, df_temp], axis=0)\n",
    "        \n",
    "    print('Normalized per file')\n",
    "    utils.get_data_overview(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "Normalized per file\n",
    "Shape of DataFrame (6022044, 13)\n",
    "AoP: mean:  8.476422646032742e-18 std:  1.0000000830282978 min:  -2.7786048713806513 max:  4.808802668585217 median:  -0.1360668248199314\n",
    "VADcurrent: mean:  4.0852959033440655e-17 std:  1.0000000830282976 min:  -11.981886874581654 max:  17.447844556111704 median:  -0.07346303264848664\n",
    "VadQ: mean:  -4.832882399519781e-18 std:  1.0000000830282976 min:  -8.201428557907775 max:  3.3115737016978097 median:  -0.08852087878540464\n",
    "LVP: mean:  1.666022936553206e-18 std:  1.0000000830282978 min:  -2.7810397103291944 max:  3.576518816510218 median:  -0.6391708073508791\n",
    "LVtot_kalibriert: mean:  -2.1247691955701228e-17 std:  1.0000000830282978 min:  -3.7267938151892253 max:  3.4179702854250453 median:  0.17636830479941046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NORM_PHASE_1 == True or NORM_ALL_DATA == True:\n",
    "    path = \"/home/johann/Desktop/Uni/Masterarbeit/Cycle_GAN/csv_export_files_alle_Daten/csv_export_files\" \n",
    "    csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    scaler = StandardScaler() \n",
    "    for f in csv_files:\n",
    "        df_temp = pd.read_csv(f, sep=\";\")\n",
    "        df_temp = utils.drop_cols(df_temp)\n",
    "        df_temp = df_temp.dropna()\n",
    "        df_temp = utils.remove_strings(df_temp)  \n",
    "        df_temp = utils.subsample(df_temp, 10)\n",
    "        # df_temp = utils.normalize_df(df_temp, scaler) \n",
    "        df = pd.concat([df, df_temp], axis=0)\n",
    "\n",
    "    df = df.groupby('animal').filter(lambda x: len(x) > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get overview of the data before normalization\n",
    "# utils.get_data_overview(df_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "\n",
    "AoP: mean:  48.30846696781112 std:  15.156141832600728 min:  15.84199 max:  140.4831 median:  46.1051\n",
    "\n",
    "VADcurrent: mean:  0.5541030227058161 std:  0.20180199960363357 min:  -0.9118687 max:  5.10126 median:  0.511567\n",
    "\n",
    "VadQ: mean:  2.177537563636682 std:  0.9466818061058603 min:  -1.511544 max:  6.007812 median:  2.165501\n",
    "\n",
    "LVP: mean:  27.259501107205093 std:  24.888557742090942 min:  -61.03938 max:  168.5278 median:  11.6282\n",
    "\n",
    "LVtot_kalibriert: mean:  90.4793272339531 std:  42.87935237198888 min:  -33.8681644353909 max:  320.181386525449 median:  88.4587843298934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized by phase 1\n",
      "Shape of DataFrame (26499, 14)\n",
      "AoP: mean:  36.62172814517554 std:  6.659436756555444 min:  24.620841999945696 max:  54.55852600000799 median:  36.853647000010824\n",
      "VADcurrent: mean:  0.4333234524499152 std:  0.07547782383799573 min:  0.1964648599996508 max:  0.6942468099987309 median:  0.4299174400002812\n",
      "VadQ: mean:  1.6625940614921868 std:  0.7164357519619515 min:  0.0582500490017992 max:  3.1618874999912805 median:  1.6764705000023241\n",
      "LVP: mean:  26.509833458900093 std:  21.351947781166995 min:  5.438838399975793 max:  66.84940199990524 median:  12.786040999999997\n",
      "LVtot_kalibriert: mean:  116.70825634421752 std:  16.05123293505755 min:  78.52332564361859 max:  164.16726023773663 median:  117.80890780431218\n"
     ]
    }
   ],
   "source": [
    "# if NORMALIZATION == True and NORM_PHASE_1 == True:  \n",
    "print('Normalized by phase 1')\n",
    "df = utils.normalize(df, scaler, phase1 = True)\n",
    "utils.get_data_overview(df_temp)\n",
    "\n",
    "# # if NORMALIZATION == True and NORM_ALL_DATA == True:\n",
    "# print('Normalized with all the data')\n",
    "# df_temp = utils.normalize(df, scaler, phase1 = False)\n",
    "# utils.get_data_overview(df_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "Normalized by phase 1\n",
    "Shape of DataFrame (11931572, 13)\n",
    "AoP: mean:  -0.06557444648713584 std:  0.8878459645849367 min:  -3.088167190570084 max:  4.808836670894062 median:  -0.1931671327622163\n",
    "VADcurrent: mean:  0.32194796372694146 std:  1.0892522152700856 min:  -12.272475323878714 max:  19.724014576100192 median:  0.12902850124052548\n",
    "VadQ: mean:  0.2397314419752238 std:  0.9637863092666007 min:  -5.488560529279074 max:  4.244330530595154 median:  0.2580906882690985\n",
    "LVP: mean:  -0.05540577231887373 std:  0.9397205691162268 min:  -2.89908819574177 max:  4.781273048784575 median:  -0.6147855178422799\n",
    "LVtot_kalibriert: mean:  0.2809593158841215 std:  1.1933054809214665 min:  -4.341492555302559 max:  3.768923461706554 median:  0.19872751888704757\n",
    "\n",
    "Normalized with all the data\n",
    "Shape of DataFrame (11931572, 13)\n",
    "AoP: mean:  0.15143322806935683 std:  1.6548883870195956 min:  -13.965436345696867 max:  12.14236505608361 median:  -0.08535793751574346\n",
    "VADcurrent: mean:  0.5293288463125844 std:  1.4889912744757337 min:  -14.777772394223327 max:  23.10131774091906 median:  0.35366173081445984\n",
    "VadQ: mean:  0.24893508799792072 std:  1.4943442918122685 min:  -31.410083873273255 max:  6.632881665829332 median:  0.35879103761717\n",
    "LVP: mean:  -0.033408512465791164 std:  1.0050075603646809 min:  -2.9248941019933343 max:  5.478443864393581 median:  -0.6269452169984315\n",
    "LVtot_kalibriert: mean:  0.34259703281089615 std:  1.4799829735049879 min:  -6.974893133985444 max:  4.335202195375505 median:  0.2114695301475898"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much data per phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset with data from phase 1 (11931572, 14)\n",
      "Size of Phase 1:  (751120, 14)\n",
      "Size of Phase 2:  (1370162, 14)\n",
      "Size of Phase 3:  (1371092, 14)\n",
      "Size of Phase 4:  (1369343, 14)\n",
      "SIze of Phase 5:  (1160327, 14)\n"
     ]
    }
   ],
   "source": [
    "print('Size of the dataset with data from phase 1',df.shape)\n",
    "print('Size of Phase 1: ', df.loc[df['Phasenzuordnung'] == 1].shape)\n",
    "print('Size of Phase 2: ', df.loc[df['Phasenzuordnung'] == 2].shape)\n",
    "print('Size of Phase 3: ', df.loc[df['Phasenzuordnung'] == 3].shape)\n",
    "print('Size of Phase 4: ', df.loc[df['Phasenzuordnung'] == 4].shape)\n",
    "print('SIze of Phase 5: ', df.loc[df['Phasenzuordnung'] == 5].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Phase 1:  0.06295230837981784\n",
      "Percentage of Phase 2:  0.11483499408124931\n",
      "Percentage of Phase 3:  0.11491293854657207\n",
      "Percentage of Phase 4:  0.11476635266501346\n",
      "Percentage of Phase 5:  0.09724845980060297\n"
     ]
    }
   ],
   "source": [
    "# get percentage of each phase\n",
    "print('Percentage of Phase 1: ', df.loc[df['Phasenzuordnung'] == 1].shape[0]/df.shape[0])\n",
    "print('Percentage of Phase 2: ', df.loc[df['Phasenzuordnung'] == 2].shape[0]/df.shape[0])\n",
    "print('Percentage of Phase 3: ', df.loc[df['Phasenzuordnung'] == 3].shape[0]/df.shape[0])\n",
    "print('Percentage of Phase 4: ', df.loc[df['Phasenzuordnung'] == 4].shape[0]/df.shape[0])\n",
    "print('Percentage of Phase 5: ', df.loc[df['Phasenzuordnung'] == 5].shape[0]/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different animals:  26\n"
     ]
    }
   ],
   "source": [
    "# Get number of different animals\n",
    "print('Number of different animals: ', len(df['animal'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2.  3.  1.  9. 10.  4. nan]\n"
     ]
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Phasenzuordnung'] == 1:\n",
    "        df.at[index, 'intervention'] = 0\n",
    "    elif row['intervention'] == 10:\n",
    "        if row['contractility'] == 1.0:\n",
    "            df.at[index, 'intervention'] = 0      # contractility = 1.0 - could be ignored? - phase 0?\n",
    "        if row['contractility'] == 3.0:\n",
    "            df.at[index, 'intervention'] = 9      # contractility = 3.0                                        \n",
    "        if row['contractility'] == 4.0:\n",
    "            df.at[index, 'intervention'] = 10    # contractility = 4.0\n",
    "\n",
    "#get unique intervention\n",
    "print(df['intervention'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with intervention = 0\n",
    "df = df[df.intervention != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'afterload'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'afterload'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/johann/Desktop/GitHub repos/Master_thesis/Data_exploration.ipynb Cell 19\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/johann/Desktop/GitHub%20repos/Master_thesis/Data_exploration.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# get value counts of intervention 1, when also intervention 2 is present\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/johann/Desktop/GitHub%20repos/Master_thesis/Data_exploration.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m int_1 \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mloc[df[\u001b[39m'\u001b[39m\u001b[39mintervention\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/johann/Desktop/GitHub%20repos/Master_thesis/Data_exploration.ipynb#X24sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m Vnormal \u001b[39m=\u001b[39m int_1\u001b[39m.\u001b[39mloc[int_1[\u001b[39m'\u001b[39;49m\u001b[39mafterload\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/johann/Desktop/GitHub%20repos/Master_thesis/Data_exploration.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m Vnormal\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'afterload'"
     ]
    }
   ],
   "source": [
    "# get value counts of intervention 1, when also intervention 2 is present\n",
    "int_1 = df.loc[df['intervention'] == 1]\n",
    "Vnormal = int_1.loc[int_1['afterload'] == 1]\n",
    "Vnormal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often does each intervention occur?\n",
    "print('Number of different interventions: ', len(df['intervention'].unique()))\n",
    "print('Number of each intervention: ', df['intervention'].value_counts())\n",
    "# get percentage of each intervention\n",
    "print('Percentage of each intervention: ', df['intervention'].value_counts()/df.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9de897a1f02868636d0ac53130d687147b532c1438896437dda8e287739e6223"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
