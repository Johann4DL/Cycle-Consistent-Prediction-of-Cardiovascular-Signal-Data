{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johann/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "NORMALIZATION = True\n",
    "NORM_ALL_DATA = False\n",
    "NORM_PHASE_1  = False\n",
    "NORM_PER_FILE = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_overview(df):\n",
    "    print('Shape of DataFrame', df.shape)\n",
    "    print('AoP: mean: ', df[\"AoP\" ].mean(), 'std: ', df[\"AoP\" ].std(), 'min: ', df[\"AoP\" ].min(), 'max: ', df[\"AoP\" ].max(), 'median: ', df[\"AoP\" ].median())\n",
    "    print('VADcurrent: mean: ', df[\"VADcurrent\" ].mean(), 'std: ', df[\"VADcurrent\" ].std(), 'min: ', df[\"VADcurrent\" ].min(), 'max: ', df[\"VADcurrent\" ].max(), 'median: ', df[\"VADcurrent\" ].median())\n",
    "    print('VadQ: mean: ', df[\"VadQ\" ].mean(), 'std: ', df[\"VadQ\" ].std(), 'min: ', df[\"VadQ\" ].min(), 'max: ', df[\"VadQ\" ].max(), 'median: ', df[\"VadQ\" ].median())\n",
    "    print('LVP: mean: ', df[\"LVP\" ].mean(), 'std: ', df[\"LVP\" ].std(), 'min: ', df[\"LVP\" ].min(), 'max: ', df[\"LVP\" ].max(), 'median: ', df[\"LVP\" ].median())\n",
    "    print('LVtot_kalibriert: mean: ', df[\"LVtot_kalibriert\" ].mean(), 'std: ', df[\"LVtot_kalibriert\" ].std(), 'min: ', df[\"LVtot_kalibriert\" ].min(), 'max: ', df[\"LVtot_kalibriert\" ].max(), 'median: ', df[\"LVtot_kalibriert\" ].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not NORMALIZATION:\n",
    "    path = \"/home/johann/Desktop/Uni/Masterarbeit/Cycle_GAN/csv_export_files_alle_Daten/csv_export_files\" \n",
    "    csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    scaler = StandardScaler() \n",
    "    for f in csv_files:\n",
    "        df_temp = pd.read_csv(f, sep=\";\")\n",
    "        df_temp = utils.drop_cols(df_temp)\n",
    "        df_temp = df_temp.dropna()\n",
    "        df_temp = utils.remove_strings(df_temp)  \n",
    "        df = pd.concat([df, df_temp], axis=0)\n",
    "        \n",
    "    get_data_overview(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get mean, standard deviation, min, max and median of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_by_all_phases(df, scaler):\n",
    "    '''\n",
    "    Normalize the data by the whole dataframe\n",
    "    '''\n",
    "    cols = df.columns.tolist()\n",
    "    df = df.to_numpy() \n",
    "    scaler.fit(df)\n",
    "    transformed_data = scaler.transform(df)\n",
    "    df = pd.DataFrame(transformed_data, columns=cols)  \n",
    "    return df\n",
    "\n",
    "def normalize_by_phase1(df, scaler):\n",
    "    '''\n",
    "    Normalize the data by the first phase\n",
    "    '''\n",
    "    cols = df.columns.tolist()\n",
    "    phase_1 = df.loc[df['Phasenzuordnung'] == 1]\n",
    "    phase_1 = phase_1.to_numpy() \n",
    "    df = df.to_numpy()  \n",
    "    scaler.fit(phase_1)\n",
    "    transformed_data = scaler.transform(df)\n",
    "    df = pd.DataFrame(transformed_data, columns=cols)  \n",
    "    return df\n",
    "\n",
    "def normalize(df, scaler, phase1 = True):\n",
    "    df_IPA = df[['intervention', 'Phasenzuordnung', 'animal']]\n",
    "    df_temp = pd.DataFrame()\n",
    "    NORMALIZE = normalize_by_phase1\n",
    "    if phase1 == True:\n",
    "        NORMALIZE = normalize_by_all_phases\n",
    "\n",
    "    for animal in df['animal'].unique():\n",
    "        # split df into separate dataframes for each animal\n",
    "        df_animal = df.loc[df['animal'] == animal]\n",
    "        df_animal = NORMALIZE(df_animal, scaler) # normalize by phase 1\n",
    "        # append df_animal to df_temp\n",
    "        df_temp = pd.concat([df_temp, df_animal], axis=0, ignore_index=True)\n",
    "\n",
    "    df = df_temp\n",
    "    df = df.drop(columns=['intervention', 'Phasenzuordnung', 'animal'])\n",
    "    df.dropna(inplace=True)\n",
    "    df = df.join(df_IPA)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized per file\n",
      "Shape of DataFrame (6022044, 13)\n",
      "AoP: mean:  8.476422646032742e-18 std:  1.0000000830282978 min:  -2.7786048713806513 max:  4.808802668585217 median:  -0.1360668248199314\n",
      "VADcurrent: mean:  4.0852959033440655e-17 std:  1.0000000830282976 min:  -11.981886874581654 max:  17.447844556111704 median:  -0.07346303264848664\n",
      "VadQ: mean:  -4.832882399519781e-18 std:  1.0000000830282976 min:  -8.201428557907775 max:  3.3115737016978097 median:  -0.08852087878540464\n",
      "LVP: mean:  1.666022936553206e-18 std:  1.0000000830282978 min:  -2.7810397103291944 max:  3.576518816510218 median:  -0.6391708073508791\n",
      "LVtot_kalibriert: mean:  -2.1247691955701228e-17 std:  1.0000000830282978 min:  -3.7267938151892253 max:  3.4179702854250453 median:  0.17636830479941046\n"
     ]
    }
   ],
   "source": [
    "if NORMALIZATION == True and NORM_PER_FILE == True:\n",
    "    path = \"/home/johann/Desktop/Uni/Masterarbeit/Cycle_GAN/csv_export_files_alle_Daten/csv_export_files\" \n",
    "    csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    scaler = StandardScaler() \n",
    "    for f in csv_files:\n",
    "        df_temp = pd.read_csv(f, sep=\";\")\n",
    "        df_temp = utils.drop_cols(df_temp)\n",
    "        df_temp = df_temp.dropna()\n",
    "        df_temp = utils.remove_strings(df_temp)  \n",
    "        df_temp = utils.subsample(df_temp, 10)\n",
    "        df_temp = normalize(df_temp, scaler, phase1 = True)\n",
    "        df = pd.concat([df, df_temp], axis=0)\n",
    "        \n",
    "    print('Normalized per file')\n",
    "    get_data_overview(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized per file\n",
    "Shape of DataFrame (6022044, 13)\n",
    "AoP: mean:  8.476422646032742e-18 std:  1.0000000830282978 min:  -2.7786048713806513 max:  4.808802668585217 median:  -0.1360668248199314\n",
    "VADcurrent: mean:  4.0852959033440655e-17 std:  1.0000000830282976 min:  -11.981886874581654 max:  17.447844556111704 median:  -0.07346303264848664\n",
    "VadQ: mean:  -4.832882399519781e-18 std:  1.0000000830282976 min:  -8.201428557907775 max:  3.3115737016978097 median:  -0.08852087878540464\n",
    "LVP: mean:  1.666022936553206e-18 std:  1.0000000830282978 min:  -2.7810397103291944 max:  3.576518816510218 median:  -0.6391708073508791\n",
    "LVtot_kalibriert: mean:  -2.1247691955701228e-17 std:  1.0000000830282978 min:  -3.7267938151892253 max:  3.4179702854250453 median:  0.17636830479941046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/johann/Desktop/Uni/Masterarbeit/Cycle_GAN/csv_export_files_alle_Daten/csv_export_files\" \n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "scaler = StandardScaler() \n",
    "for f in csv_files:\n",
    "    df_temp = pd.read_csv(f, sep=\";\")\n",
    "    df_temp = utils.drop_cols(df_temp)\n",
    "    df_temp = df_temp.dropna()\n",
    "    df_temp = utils.remove_strings(df_temp)  \n",
    "    df_temp = utils.subsample(df_temp, 10)\n",
    "    # df_temp = utils.normalize_df(df_temp, scaler) # no normalization per file\n",
    "    df = pd.concat([df, df_temp], axis=0)\n",
    "\n",
    "df = df.groupby('animal').filter(lambda x: len(x) > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized by phase 1\n",
      "Shape of DataFrame (11931572, 13)\n",
      "AoP: mean:  -0.06557444648713584 std:  0.8878459645849367 min:  -3.088167190570084 max:  4.808836670894062 median:  -0.1931671327622163\n",
      "VADcurrent: mean:  0.32194796372694146 std:  1.0892522152700856 min:  -12.272475323878714 max:  19.724014576100192 median:  0.12902850124052548\n",
      "VadQ: mean:  0.2397314419752238 std:  0.9637863092666007 min:  -5.488560529279074 max:  4.244330530595154 median:  0.2580906882690985\n",
      "LVP: mean:  -0.05540577231887373 std:  0.9397205691162268 min:  -2.89908819574177 max:  4.781273048784575 median:  -0.6147855178422799\n",
      "LVtot_kalibriert: mean:  0.2809593158841215 std:  1.1933054809214665 min:  -4.341492555302559 max:  3.768923461706554 median:  0.19872751888704757\n"
     ]
    }
   ],
   "source": [
    "if NORMALIZATION == True and NORM_PHASE_1 == True:  \n",
    "    print('Normalized by phase 1')\n",
    "    df_temp = normalize(df, scaler, phase1 = True)\n",
    "    get_data_overview(df_temp)\n",
    "\n",
    "if NORMALIZATION == True and NORM_ALL_DATA == True:\n",
    "    print('Normalized with all the data')\n",
    "    df_temp = normalize(df, scaler, phase1 = False)\n",
    "    get_data_overview(df_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized by phase 1\n",
    "Shape of DataFrame (11931572, 13)\n",
    "AoP: mean:  -0.06557444648713584 std:  0.8878459645849367 min:  -3.088167190570084 max:  4.808836670894062 median:  -0.1931671327622163\n",
    "VADcurrent: mean:  0.32194796372694146 std:  1.0892522152700856 min:  -12.272475323878714 max:  19.724014576100192 median:  0.12902850124052548\n",
    "VadQ: mean:  0.2397314419752238 std:  0.9637863092666007 min:  -5.488560529279074 max:  4.244330530595154 median:  0.2580906882690985\n",
    "LVP: mean:  -0.05540577231887373 std:  0.9397205691162268 min:  -2.89908819574177 max:  4.781273048784575 median:  -0.6147855178422799\n",
    "LVtot_kalibriert: mean:  0.2809593158841215 std:  1.1933054809214665 min:  -4.341492555302559 max:  3.768923461706554 median:  0.19872751888704757"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized with all the data\n",
    "Shape of DataFrame (11931572, 13)\n",
    "AoP: mean:  0.15143322806935683 std:  1.6548883870195956 min:  -13.965436345696867 max:  12.14236505608361 median:  -0.08535793751574346\n",
    "VADcurrent: mean:  0.5293288463125844 std:  1.4889912744757337 min:  -14.777772394223327 max:  23.10131774091906 median:  0.35366173081445984\n",
    "VadQ: mean:  0.24893508799792072 std:  1.4943442918122685 min:  -31.410083873273255 max:  6.632881665829332 median:  0.35879103761717\n",
    "LVP: mean:  -0.033408512465791164 std:  1.0050075603646809 min:  -2.9248941019933343 max:  5.478443864393581 median:  -0.6269452169984315\n",
    "LVtot_kalibriert: mean:  0.34259703281089615 std:  1.4799829735049879 min:  -6.974893133985444 max:  4.335202195375505 median:  0.2114695301475898"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "\n",
    "AoP: mean:  48.30846696781112 std:  15.156141832600728 min:  15.84199 max:  140.4831 median:  46.1051\n",
    "\n",
    "VADcurrent: mean:  0.5541030227058161 std:  0.20180199960363357 min:  -0.9118687 max:  5.10126 median:  0.511567\n",
    "\n",
    "VadQ: mean:  2.177537563636682 std:  0.9466818061058603 min:  -1.511544 max:  6.007812 median:  2.165501\n",
    "\n",
    "LVP: mean:  27.259501107205093 std:  24.888557742090942 min:  -61.03938 max:  168.5278 median:  11.6282\n",
    "\n",
    "LVtot_kalibriert: mean:  90.4793272339531 std:  42.87935237198888 min:  -33.8681644353909 max:  320.181386525449 median:  88.4587843298934"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much data per phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of the dataset with data from phase 1',df.shape)\n",
    "print('Size of Phase 1: ', df.loc[df['Phasenzuordnung'] == 1].shape)\n",
    "print('Size of Phase 2: ', df.loc[df['Phasenzuordnung'] == 2].shape)\n",
    "print('Size of Phase 3: ', df.loc[df['Phasenzuordnung'] == 3].shape)\n",
    "print('Size of Phase 4: ', df.loc[df['Phasenzuordnung'] == 4].shape)\n",
    "print('SIze of Phase 5: ', df.loc[df['Phasenzuordnung'] == 5].shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9de897a1f02868636d0ac53130d687147b532c1438896437dda8e287739e6223"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
