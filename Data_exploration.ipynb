{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johann/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import utils\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "NORMALIZATION = True\n",
    "NORM_ALL_DATA = False\n",
    "NORM_PHASE_1  = False\n",
    "NORM_PER_FILE = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not NORMALIZATION:\n",
    "    path = \"/home/johann/Desktop/Uni/Masterarbeit/Cycle_GAN/csv_export_files_alle_Daten/csv_export_files\" \n",
    "    csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    scaler = StandardScaler() \n",
    "    for f in csv_files:\n",
    "        df_temp = pd.read_csv(f, sep=\";\")\n",
    "        df_temp = utils.drop_cols(df_temp)\n",
    "        df_temp = df_temp.dropna()\n",
    "        df_temp = utils.remove_strings(df_temp)  \n",
    "        df = pd.concat([df, df_temp], axis=0)\n",
    "        \n",
    "    utils.get_data_overview(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get mean, standard deviation, min, max and median of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized per file\n",
      "Shape of DataFrame (6022044, 16)\n",
      "AoP: mean:  48.30847789525583 std:  15.153152923498263 min:  15.856160000083037 max:  140.38751000000047 median:  46.10740599997371\n",
      "VADcurrent: mean:  0.5541030138440085 std:  0.20167086814548843 min:  -0.8063268900004914 max:  5.092731500000809 median:  0.5115693499993199\n",
      "VadQ: mean:  2.1775348983652427 std:  0.9465230017230916 min:  -1.4067543999917689 max:  5.993453799997951 median:  2.1655909499982045\n",
      "LVP: mean:  27.25951742579371 std:  24.875284239815052 min:  -60.63108600000123 max:  166.53891999996267 median:  11.646741000042311\n",
      "LVtot_kalibriert: mean:  90.47925277948431 std:  42.87621222411684 min:  -33.8161546293486 max:  320.06734372721985 median:  88.45988649118226\n"
     ]
    }
   ],
   "source": [
    "if NORMALIZATION == True and NORM_PER_FILE == True:\n",
    "    path = \"/home/johann/Desktop/Uni/Masterarbeit/Cycle_GAN/csv_export_files_alle_Daten/csv_export_files\" \n",
    "    csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    scaler = StandardScaler() \n",
    "    for f in csv_files:\n",
    "        df_temp = pd.read_csv(f, sep=\";\")\n",
    "        df_temp = utils.drop_cols(df_temp)\n",
    "        df_temp = df_temp.dropna()\n",
    "        df_temp = utils.remove_strings(df_temp)  \n",
    "        df_temp = utils.subsample(df_temp, 10)\n",
    "        #df_temp = utils.normalize(df_temp, scaler, phase1 = True)\n",
    "        df = pd.concat([df, df_temp], axis=0)\n",
    "        \n",
    "    print('Normalized per file')\n",
    "    utils.get_data_overview(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "Normalized per file\n",
    "Shape of DataFrame (6022044, 13)\n",
    "AoP: mean:  8.476422646032742e-18 std:  1.0000000830282978 min:  -2.7786048713806513 max:  4.808802668585217 median:  -0.1360668248199314\n",
    "VADcurrent: mean:  4.0852959033440655e-17 std:  1.0000000830282976 min:  -11.981886874581654 max:  17.447844556111704 median:  -0.07346303264848664\n",
    "VadQ: mean:  -4.832882399519781e-18 std:  1.0000000830282976 min:  -8.201428557907775 max:  3.3115737016978097 median:  -0.08852087878540464\n",
    "LVP: mean:  1.666022936553206e-18 std:  1.0000000830282978 min:  -2.7810397103291944 max:  3.576518816510218 median:  -0.6391708073508791\n",
    "LVtot_kalibriert: mean:  -2.1247691955701228e-17 std:  1.0000000830282978 min:  -3.7267938151892253 max:  3.4179702854250453 median:  0.17636830479941046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NORM_PHASE_1 == True or NORM_ALL_DATA == True:\n",
    "    path = \"/home/johann/Desktop/Uni/Masterarbeit/Cycle_GAN/csv_export_files_alle_Daten/csv_export_files\" \n",
    "    csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    scaler = StandardScaler() \n",
    "    for f in csv_files:\n",
    "        df_temp = pd.read_csv(f, sep=\";\")\n",
    "        df_temp = utils.drop_cols(df_temp)\n",
    "        df_temp = df_temp.dropna()\n",
    "        df_temp = utils.remove_strings(df_temp)  \n",
    "        df_temp = utils.subsample(df_temp, 10)\n",
    "        # df_temp = utils.normalize_df(df_temp, scaler) # no normalization per file\n",
    "        df = pd.concat([df, df_temp], axis=0)\n",
    "\n",
    "    df = df.groupby('animal').filter(lambda x: len(x) > 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get overview of the data before normalization\n",
    "# utils.get_data_overview(df_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected output\n",
    "\n",
    "AoP: mean:  48.30846696781112 std:  15.156141832600728 min:  15.84199 max:  140.4831 median:  46.1051\n",
    "\n",
    "VADcurrent: mean:  0.5541030227058161 std:  0.20180199960363357 min:  -0.9118687 max:  5.10126 median:  0.511567\n",
    "\n",
    "VadQ: mean:  2.177537563636682 std:  0.9466818061058603 min:  -1.511544 max:  6.007812 median:  2.165501\n",
    "\n",
    "LVP: mean:  27.259501107205093 std:  24.888557742090942 min:  -61.03938 max:  168.5278 median:  11.6282\n",
    "\n",
    "LVtot_kalibriert: mean:  90.4793272339531 std:  42.87935237198888 min:  -33.8681644353909 max:  320.181386525449 median:  88.4587843298934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if NORMALIZATION == True and NORM_PHASE_1 == True:  \n",
    "    print('Normalized by phase 1')\n",
    "    df_temp = utils.normalize(df, scaler, phase1 = True)\n",
    "    utils.get_data_overview(df_temp)\n",
    "\n",
    "if NORMALIZATION == True and NORM_ALL_DATA == True:\n",
    "    print('Normalized with all the data')\n",
    "    df_temp = utils.normalize(df, scaler, phase1 = False)\n",
    "    utils.get_data_overview(df_temp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output:\n",
    "\n",
    "Normalized by phase 1\n",
    "Shape of DataFrame (11931572, 13)\n",
    "AoP: mean:  -0.06557444648713584 std:  0.8878459645849367 min:  -3.088167190570084 max:  4.808836670894062 median:  -0.1931671327622163\n",
    "VADcurrent: mean:  0.32194796372694146 std:  1.0892522152700856 min:  -12.272475323878714 max:  19.724014576100192 median:  0.12902850124052548\n",
    "VadQ: mean:  0.2397314419752238 std:  0.9637863092666007 min:  -5.488560529279074 max:  4.244330530595154 median:  0.2580906882690985\n",
    "LVP: mean:  -0.05540577231887373 std:  0.9397205691162268 min:  -2.89908819574177 max:  4.781273048784575 median:  -0.6147855178422799\n",
    "LVtot_kalibriert: mean:  0.2809593158841215 std:  1.1933054809214665 min:  -4.341492555302559 max:  3.768923461706554 median:  0.19872751888704757\n",
    "\n",
    "Normalized with all the data\n",
    "Shape of DataFrame (11931572, 13)\n",
    "AoP: mean:  0.15143322806935683 std:  1.6548883870195956 min:  -13.965436345696867 max:  12.14236505608361 median:  -0.08535793751574346\n",
    "VADcurrent: mean:  0.5293288463125844 std:  1.4889912744757337 min:  -14.777772394223327 max:  23.10131774091906 median:  0.35366173081445984\n",
    "VadQ: mean:  0.24893508799792072 std:  1.4943442918122685 min:  -31.410083873273255 max:  6.632881665829332 median:  0.35879103761717\n",
    "LVP: mean:  -0.033408512465791164 std:  1.0050075603646809 min:  -2.9248941019933343 max:  5.478443864393581 median:  -0.6269452169984315\n",
    "LVtot_kalibriert: mean:  0.34259703281089615 std:  1.4799829735049879 min:  -6.974893133985444 max:  4.335202195375505 median:  0.2114695301475898"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much data per phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataset with data from phase 1 (6022044, 16)\n",
      "Size of Phase 1:  (751120, 16)\n",
      "Size of Phase 2:  (1370162, 16)\n",
      "Size of Phase 3:  (1371092, 16)\n",
      "Size of Phase 4:  (1369343, 16)\n",
      "SIze of Phase 5:  (1160327, 16)\n"
     ]
    }
   ],
   "source": [
    "print('Size of the dataset with data from phase 1',df.shape)\n",
    "print('Size of Phase 1: ', df.loc[df['Phasenzuordnung'] == 1].shape)\n",
    "print('Size of Phase 2: ', df.loc[df['Phasenzuordnung'] == 2].shape)\n",
    "print('Size of Phase 3: ', df.loc[df['Phasenzuordnung'] == 3].shape)\n",
    "print('Size of Phase 4: ', df.loc[df['Phasenzuordnung'] == 4].shape)\n",
    "print('SIze of Phase 5: ', df.loc[df['Phasenzuordnung'] == 5].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Phase 1:  0.12472841447189692\n",
      "Percentage of Phase 2:  0.22752440865593143\n",
      "Percentage of Phase 3:  0.2276788412705055\n",
      "Percentage of Phase 4:  0.2273884083211614\n",
      "Percentage of Phase 5:  0.19267992728050476\n"
     ]
    }
   ],
   "source": [
    "# get percentage of each phase\n",
    "print('Percentage of Phase 1: ', df.loc[df['Phasenzuordnung'] == 1].shape[0]/df.shape[0])\n",
    "print('Percentage of Phase 2: ', df.loc[df['Phasenzuordnung'] == 2].shape[0]/df.shape[0])\n",
    "print('Percentage of Phase 3: ', df.loc[df['Phasenzuordnung'] == 3].shape[0]/df.shape[0])\n",
    "print('Percentage of Phase 4: ', df.loc[df['Phasenzuordnung'] == 4].shape[0]/df.shape[0])\n",
    "print('Percentage of Phase 5: ', df.loc[df['Phasenzuordnung'] == 5].shape[0]/df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different animals:  25\n"
     ]
    }
   ],
   "source": [
    "# Get number of different animals\n",
    "print('Number of different animals: ', len(df['animal'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  3. 10.  2.  4.  9.]\n"
     ]
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Phasenzuordnung'] == 1:\n",
    "        df.at[index, 'intervention'] = 0\n",
    "    elif row['intervention'] == 10:\n",
    "        if row['contractility'] == 1.0:\n",
    "            df.at[index, 'intervention'] = 0      # contractility = 1.0 - could be ignored? - phase 0?\n",
    "        if row['contractility'] == 3.0:\n",
    "            df.at[index, 'intervention'] = 9      # contractility = 3.0                                        \n",
    "        if row['contractility'] == 4.0:\n",
    "            df.at[index, 'intervention'] = 10    # contractility = 4.0\n",
    "\n",
    "#get unique intervention\n",
    "print(df['intervention'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns with intervention = 0\n",
    "df = df[df.intervention != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2162838, 16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get value counts of intervention 1, when also intervention 2 is present\n",
    "int_1 = df.loc[df['intervention'] == 1]\n",
    "Vnormal = int_1.loc[int_1['afterload'] == 1]\n",
    "Vnormal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different interventions:  6\n",
      "Number of each intervention:  1.0     2162838\n",
      "3.0     1532302\n",
      "10.0    1212463\n",
      "2.0       34544\n",
      "4.0       26222\n",
      "9.0       19533\n",
      "Name: intervention, dtype: int64\n",
      "Percentage of each intervention:  1.0     0.433617\n",
      "3.0     0.307204\n",
      "10.0    0.243081\n",
      "2.0     0.006926\n",
      "4.0     0.005257\n",
      "9.0     0.003916\n",
      "Name: intervention, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# How often does each intervention occur?\n",
    "print('Number of different interventions: ', len(df['intervention'].unique()))\n",
    "print('Number of each intervention: ', df['intervention'].value_counts())\n",
    "# get percentage of each intervention\n",
    "print('Percentage of each intervention: ', df['intervention'].value_counts()/df.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9de897a1f02868636d0ac53130d687147b532c1438896437dda8e287739e6223"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
