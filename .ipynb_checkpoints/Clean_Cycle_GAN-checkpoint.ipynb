{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johann/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import utils\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm as tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import load_csv, drop_cols, remove_strings, groupedAvg, subsample, normalize\n",
    "from create_dataset import AnimalDatasetEmbedding, UnpairedEmbeddingsDataset\n",
    "from generators import  OneHotGenerator\n",
    "from discriminators import MultiChannelDiscriminator \n",
    "import os\n",
    "import glob\n",
    "import generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "PHASES = [1, 3]\n",
    "UNPAIRED = True \n",
    "SKIPCONNECTIONS = True\n",
    "EMBEDDING = True\n",
    "if EMBEDDING == True:\n",
    "    DOWN = False\n",
    "    BOTTLENECK = True\n",
    "ONEHOTENCODING = True\n",
    "\n",
    "# LR scheduler\n",
    "MultiStepLR = False\n",
    "ReduceLROnPlateau = True\n",
    "\n",
    "if MultiStepLR  == True and ReduceLROnPlateau == True:\n",
    "    #raise error\n",
    "    print(\"Error: Only one learning rate scheduler can be used at a time.\")\n",
    "    raise (NameError)\n",
    "if MultiStepLR == False and ReduceLROnPlateau == False:\n",
    "    print(\"Error: At least one learning rate scheduler must be used.\")\n",
    "    raise (NameError)\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 1e-2 \n",
    "NUM_WORKERS = 16\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "SIG_A = \"AoP\"           # Drucksignal Hauptschlagader = Aortendruck\n",
    "SIG_B = \"VADcurrent\"    # VAD Strom [A] â€“ Pumpemstrom in Ampere\n",
    "SIG_C = \"VadQ\"          # Fluss durch VAD (VAD = Ventrikular assistance device = Pumpe) = Pumpenfluss\n",
    "SIG_D = \"LVP\"           # Ventrikeldruck links = Drucksignal der linken Herzkammer\n",
    "TARGET = \"LVtot_kalibriert\"  # RVtot_kalibriert existiert auch\n",
    "source_signals = [SIG_D]\n",
    "CHANNELS = len(source_signals)\n",
    "WINDOW = 256\n",
    "\n",
    "GENERATION_AFTER_EPOCH = NUM_EPOCHS # number of epochs after which the model generates a sample\n",
    "\n",
    "# Use adversarial loss\n",
    "GAN_LOSS = True   # adversarial loss\n",
    "LAMBDA_GAN = 1.0\n",
    "# Use cycle consistency loss\n",
    "CYCLE = True\n",
    "LAMBDA_CYCLE = 1.0\n",
    "# Use supervised loss\n",
    "SUPERVISED = False \n",
    "LAMBDA_SUPERVISED = 1.0\n",
    "# Use Identity loss\n",
    "IDENTITY = False\n",
    "LAMBDA_IDENTITY = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load all data and preprocess\n",
    "\n",
    "Subsamplen, normalisieren pro Datei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/johann/Desktop/Uni/Masterarbeit/Cycle_GAN/csv_export_files_alle_Daten/csv_export_files\" \n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "  \n",
    "df = pd.DataFrame()\n",
    "scaler = StandardScaler() \n",
    "# loop over the list of csv files\n",
    "for f in csv_files:\n",
    "      \n",
    "    # read the csv file\n",
    "    df_temp = pd.read_csv(f, sep=\";\")\n",
    "    df_temp = utils.drop_cols(df_temp)\n",
    "    df_temp = df_temp.dropna()\n",
    "    df_temp = utils.remove_strings(df_temp)\n",
    "    df_temp = utils.subsample(df_temp, 10)\n",
    "    df_temp = utils.normalize(df_temp, scaler, phase1 = True)  \n",
    "      \n",
    "    # print the content\n",
    "    df = pd.concat([df, df_temp], axis=0)\n",
    "    \n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the data\n",
    "# utils.visualize(df, [SIG_A, SIG_B, SIG_C, SIG_D, 'intervention', 'Phasenzuordnung', 'animal'], 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select part of data to use in experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select which phases to use\n",
    "df = df.loc[df['Phasenzuordnung'].isin(PHASES)]\n",
    "print('Size of the dataset after selecting Phasenzuordnung 1',df.shape)\n",
    "\n",
    "print('Size of the dataset with data from phase 1',df.shape)\n",
    "print('Size of Phase 1: ', df.loc[df['Phasenzuordnung'] == 1].shape)\n",
    "print('Size of Phase 2: ', df.loc[df['Phasenzuordnung'] == 2].shape)\n",
    "print('Size of Phase 3: ', df.loc[df['Phasenzuordnung'] == 3].shape)\n",
    "print('Size of Phase 4: ', df.loc[df['Phasenzuordnung'] == 4].shape)\n",
    "print('SIze of Phase 5: ', df.loc[df['Phasenzuordnung'] == 5].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get unique interventions in df\n",
    "# df['intervention'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # in Phase 1 nothing happens -> intervention information is not useful\n",
    "# for index, row in df.iterrows():\n",
    "#     if row['Phasenzuordnung'] == 1:\n",
    "#         # change the intervention to 11\n",
    "#         df.at[index, 'intervention'] = 6\n",
    "#     if row['intervention'] == 10:\n",
    "#         # change the intervention to 5\n",
    "#         df.at[index, 'intervention'] = 5\n",
    "        \n",
    "\n",
    "# # get unique interventions in df\n",
    "# df['intervention'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop animals with less than 10 data points\n",
    "We drop animals from the dataframe, if they have less than 10 data points. Initially, we have 56 animals and after dropping those with close to no data points, we are left with 25 animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df['animal'].unique()))\n",
    "# remove animals with less than 10 data points\n",
    "df = df.groupby('animal').filter(lambda x: len(x) > 10)\n",
    "print('Number of animals after removing those with less than 10 data points: ', len(df['animal'].unique()))\n",
    "\n",
    "# get all differnent animals\n",
    "animals = df['animal'].unique()\n",
    "print(animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into train and test split\n",
    "\n",
    "The 5 test animals represent 20.20924% of the whole data. If we don't use all phases, this number might be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select animals 2,3, 7, 10 and 16 as test animals\n",
    "test_animals = [3,4,8,11,17] # 3,4,8,11,17\n",
    "print('\\nTest animal(s):', test_animals)\n",
    "\n",
    "all_animals = df['animal'].unique()\n",
    "# remove test animals from train animals\n",
    "train_animals =  [x for x in all_animals if x not in test_animals]\n",
    "\n",
    "# test data\n",
    "df_test = df[df['animal'].isin(test_animals)]\n",
    "\n",
    "# change the length of the test data to a multiple of the Window size\n",
    "df_test = df_test.iloc[:len(df_test) - (len(df_test) % WINDOW)]\n",
    "\n",
    "# train dataframe with only animals from train_animals\n",
    "df_train = df[df['animal'].isin(train_animals)]\n",
    "print('\\nDifferent animal IDs after removing those that are in the test dataset: ',len(df_train['animal'].unique()))\n",
    "\n",
    "\n",
    "print('\\nTrain data shape:', df_train.shape)\n",
    "print('\\nTest data shape:', df_test.shape)\n",
    "\n",
    "# lengt of df_train\n",
    "print('\\nThe test dataset is {} percent of the whole data: '.format((len(df_test)/(len(df_train) + len(df_test))) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Generator and Discriminator\n",
    "\n",
    "We also initialize the 2 optimizers, the 2 Learning rate schedulers, the losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def double_conv_pad(in_channels, out_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1, padding_mode='zeros'),\n",
    "        nn.BatchNorm1d(out_channels),\n",
    "        nn.LeakyReLU(inplace=True),\n",
    "        nn.Dropout1d(p=0.1, inplace=False),\n",
    "        nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1, padding_mode='zeros'),\n",
    "        nn.BatchNorm1d(out_channels),\n",
    "        nn.LeakyReLU(inplace=True),\n",
    "        nn.Dropout1d(p=0.1, inplace=False),\n",
    "    )\n",
    "\n",
    "class SkipTensorEmbeddingGen(nn.Module):\n",
    "    def __init__(self, INPUTCHANNELS, OUTPUTCHANNELS, Down = True, Bottleneck = True):\n",
    "        super(SkipTensorEmbeddingGen, self).__init__()\n",
    "        self.Down = Down\n",
    "        self.Bottleneck = Bottleneck\n",
    "        self.maxpool = nn.MaxPool1d((2))  \n",
    "\n",
    "        self.source_intervention = torch.nn.Embedding(num_embeddings=11, embedding_dim=256)\n",
    "        self.source_phase = torch.nn.Embedding(num_embeddings=6, embedding_dim=256)\n",
    "\n",
    "        self.down_conv1 = double_conv_pad(INPUTCHANNELS, 32) \n",
    "        self.down_conv2 = double_conv_pad(32, 64) \n",
    "        self.down_conv3 = double_conv_pad(64, 128)\n",
    "        self.down_conv4 = double_conv_pad(128, 256)\n",
    "\n",
    "        self.target_intervention = torch.nn.Embedding(num_embeddings=11, embedding_dim=32)\n",
    "        self.target_phase = torch.nn.Embedding(num_embeddings=6, embedding_dim=32)\n",
    "\n",
    "        self.up_trans1 = nn.ConvTranspose1d(256, 128, kernel_size=(2), stride=2, padding=0)\n",
    "        self.up_conv1 = double_conv_pad(256, 128)\n",
    "        self.up_trans2 = nn.ConvTranspose1d(128, 64, kernel_size=(2), stride=2, padding=0)\n",
    "        self.up_conv2 = double_conv_pad(128, 64)\n",
    "        self.up_trans3 = nn.ConvTranspose1d(64, 32, kernel_size=(2), stride=2, padding=0)\n",
    "        self.up_conv3 = double_conv_pad(64, 32)\n",
    "\n",
    "        self.out = nn.Conv1d(32, OUTPUTCHANNELS, kernel_size=1) # kernel_size must be == 1\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Conv1d):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.ConvTranspose1d):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "        elif isinstance(module, nn.BatchNorm1d):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input, source_phase, source_intervention, target_phase, target_intervention):\n",
    "        if self.Down:\n",
    "            sp = self.source_phase(source_phase)\n",
    "            si = self.source_intervention(source_intervention)\n",
    "            input += sp + si \n",
    "        x1 = self.down_conv1(input) \n",
    "        x2 = self.maxpool(x1) \n",
    "        x3 = self.down_conv2(x2)\n",
    "        x4 = self.maxpool(x3) \n",
    "        x5 = self.down_conv3(x4) \n",
    "        x6 = self.maxpool(x5)  \n",
    "        x7 = self.down_conv4(x6)\n",
    "\n",
    "        # # decoder\n",
    "        if self.Bottleneck:\n",
    "            tp = self.target_phase(target_phase)  \n",
    "            ti = self.target_intervention(target_intervention)\n",
    "            x7 += tp + ti # target embeddings are added before upsampling  # lieber concatenating und dann fully connected to amtch the dimension\n",
    "        x = self.up_trans1(x7)\n",
    "        x = self.up_conv1(torch.cat([x, x5], 1))\n",
    "        x = self.up_trans2(x)\n",
    "        x = self.up_conv2(torch.cat([x, x3], 1))\n",
    "        x = self.up_trans3(x)\n",
    "        x = self.up_conv3(torch.cat([x, x1], 1))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorEmbeddingGen(nn.Module):\n",
    "    def __init__(self, INPUTCHANNELS, OUTPUTCHANNELS, Down = True, Bottleneck = True):\n",
    "        super(TensorEmbeddingGen, self).__init__()\n",
    "        self.Down = Down\n",
    "        self.Bottleneck = Bottleneck\n",
    "        self.maxpool = nn.MaxPool1d((2))  \n",
    "\n",
    "        self.source_intervention = torch.nn.Embedding(num_embeddings=11, embedding_dim=256)\n",
    "        self.source_phase = torch.nn.Embedding(num_embeddings=6, embedding_dim=256)\n",
    "\n",
    "        self.down_conv1 = double_conv_pad(INPUTCHANNELS, 32) \n",
    "        self.down_conv2 = double_conv_pad(32, 64) \n",
    "        self.down_conv3 = double_conv_pad(64, 128)\n",
    "        self.down_conv4 = double_conv_pad(128, 256)\n",
    "\n",
    "        self.target_intervention = torch.nn.Embedding(num_embeddings=11, embedding_dim=32)\n",
    "        self.target_phase = torch.nn.Embedding(num_embeddings=6, embedding_dim=32)\n",
    "\n",
    "        self.up_trans1 = nn.ConvTranspose1d(256, 128, kernel_size=(2), stride=2, padding=0)\n",
    "        self.up_conv1 = double_conv_pad(128, 128)\n",
    "        self.up_trans2 = nn.ConvTranspose1d(128, 64, kernel_size=(2), stride=2, padding=0)\n",
    "        self.up_conv2 = double_conv_pad(64, 64)\n",
    "        self.up_trans3 = nn.ConvTranspose1d(64, 32, kernel_size=(2), stride=2, padding=0)\n",
    "        self.up_conv3 = double_conv_pad(32, 32)\n",
    "\n",
    "        self.out = nn.Conv1d(32, OUTPUTCHANNELS, kernel_size=1) # kernel_size must be == 1\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Conv1d):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.ConvTranspose1d):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "        elif isinstance(module, nn.BatchNorm1d):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input, source_phase, source_intervention, target_phase, target_intervention):\n",
    "        if self.Down:\n",
    "            sp = self.source_phase(source_phase)\n",
    "            si = self.source_intervention(source_intervention)\n",
    "            input += sp + si \n",
    "        x1 = self.down_conv1(input) \n",
    "        x2 = self.maxpool(x1) \n",
    "        x3 = self.down_conv2(x2)\n",
    "        x4 = self.maxpool(x3) \n",
    "        x5 = self.down_conv3(x4) \n",
    "        x6 = self.maxpool(x5)  \n",
    "        x7 = self.down_conv4(x6)\n",
    "\n",
    "        # # decoder\n",
    "        if self.Bottleneck:\n",
    "            tp = self.target_phase(target_phase)  \n",
    "            ti = self.target_intervention(target_intervention)\n",
    "            x7 += tp + ti # target embeddings are added before upsampling  # lieber concatenating und dann fully connected to amtch the dimension\n",
    "        x = self.up_trans1(x7)\n",
    "        x = self.up_conv1(x)\n",
    "        x = self.up_trans2(x)\n",
    "        x = self.up_conv2(x)\n",
    "        x = self.up_trans3(x)\n",
    "        x = self.up_conv3(x)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotGenerator(nn.Module):\n",
    "    def __init__(self, INPUTCHANNELS, OUTPUTCHANNELS, WINDOWSIZE, Down = True, Bottleneck = True):\n",
    "        super(OneHotGenerator, self).__init__()\n",
    "        self.WINDOWSIZE = WINDOWSIZE\n",
    "        self.Down = Down\n",
    "        self.Bottleneck = Bottleneck\n",
    "        self.maxpool = nn.MaxPool1d((2))  \n",
    "\n",
    "        self.sourcephaseLinear = nn.Linear(7, 1)\n",
    "        self.sourceinterventionLinear = nn.Linear(7, 1)\n",
    "        self.sourceFCLinear = nn.Linear(768, 256)\n",
    "\n",
    "        self.down_conv1 = double_conv_pad(INPUTCHANNELS, 32) \n",
    "        self.down_conv2 = double_conv_pad(32, 64) \n",
    "        self.down_conv3 = double_conv_pad(64, 128)\n",
    "        self.down_conv4 = double_conv_pad(128, 256)\n",
    "\n",
    "        self.targetphaseLinear = nn.Linear(7, 32)\n",
    "        self.targetinterventionLinear = nn.Linear(7, 32)\n",
    "        self.targetFCLinear = nn.Linear(96, 32)\n",
    "\n",
    "        self.up_trans1 = nn.ConvTranspose1d(256, 128, kernel_size=(2), stride=2, padding=0)\n",
    "        self.up_conv1 = double_conv_pad(256, 128)\n",
    "        self.up_trans2 = nn.ConvTranspose1d(128, 64, kernel_size=(2), stride=2, padding=0)\n",
    "        self.up_conv2 = double_conv_pad(128, 64)\n",
    "        self.up_trans3 = nn.ConvTranspose1d(64, 32, kernel_size=(2), stride=2, padding=0)\n",
    "        self.up_conv3 = double_conv_pad(64, 32)\n",
    "\n",
    "        self.out = nn.Conv1d(32, OUTPUTCHANNELS, kernel_size=1) # kernel_size must be == 1\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Conv1d):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.ConvTranspose1d):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "        elif isinstance(module, nn.BatchNorm1d):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            module.weight.data.normal_(mean=0.0, std=1)\n",
    "            if module.bias is not None:\n",
    "                module.bias.data.zero_()\n",
    "\n",
    "\n",
    "    def forward(self, input, source_phase, source_intervention, target_phase, target_intervention):\n",
    "        # downsampling\n",
    "        if self.Down:\n",
    "            pS = F.one_hot(source_phase, num_classes=7).type(torch.FloatTensor).to(DEVICE)  #torch.Size([1, 256, 6])\n",
    "            iS = F.one_hot(source_intervention, num_classes=7).type(torch.FloatTensor).to(DEVICE) #torch.Size([1, 256, 11])\n",
    "            pS = self.sourcephaseLinear(pS).to(DEVICE)\n",
    "            iS = self.sourceinterventionLinear(iS).to(DEVICE)\n",
    "            pS = pS.reshape(input.shape[0], input.shape[1], input.shape[2]).to(DEVICE)\n",
    "            iS = iS.reshape(input.shape[0], input.shape[1], input.shape[2]).to(DEVICE)\n",
    "            # Concatenate the phase and intervention one hot encodings with the output of the last convolutional layer and reshape\n",
    "            input = torch.cat([input, pS, iS], 2) # torch.Size([1, 1, 768])\\\n",
    "            input = self.sourceFCLinear(input).to(DEVICE) \n",
    "\n",
    "        x1 = self.down_conv1(input)   \n",
    "        x2 = self.maxpool(x1) \n",
    "        x3 = self.down_conv2(x2)  \n",
    "        x4 = self.maxpool(x3) \n",
    "        x5 = self.down_conv3(x4) \n",
    "        x6 = self.maxpool(x5) \n",
    "        x7 = self.down_conv4(x6)     \n",
    "\n",
    "        # upsampling\n",
    "        if self.Bottleneck:\n",
    "            # one hot encoding\n",
    "            pT = F.one_hot(target_phase, num_classes=7).type(torch.FloatTensor).to(DEVICE)\n",
    "            iT = F.one_hot(target_intervention, num_classes=7).type(torch.FloatTensor).to(DEVICE)\n",
    "            # Fully connected Layers\n",
    "            pT = self.targetphaseLinear(pT).to(DEVICE)\n",
    "            iT = self.targetinterventionLinear(iT).to(DEVICE)\n",
    "            # Concatenate the phase and intervention one hot encodings with the output of the last convolutional layer and reshape\n",
    "            x7 = torch.cat([x7, pT, iT], 1) \n",
    "            x7 = x7.reshape(x7.shape[0], self.WINDOWSIZE, 96)\n",
    "            x7 = self.targetFCLinear(x7).to(DEVICE) \n",
    "        \n",
    "        x = self.up_trans1(x7)\n",
    "        x = self.up_conv1(torch.cat([x, x5], 1))  # skip connection\n",
    "        x = self.up_trans2(x)\n",
    "        x = self.up_conv2(torch.cat([x, x3], 1))  # skip connection\n",
    "        x = self.up_trans3(x)\n",
    "        x = self.up_conv3(torch.cat([x, x1], 1))  # skip connection\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn.functional as F\n",
    "\n",
    "# def double_conv_pad(in_channels, out_channels):\n",
    "#     return nn.Sequential(\n",
    "#         nn.Conv1d(in_channels, out_channels, kernel_size=3, padding=1, padding_mode='zeros'),\n",
    "#         nn.BatchNorm1d(out_channels),\n",
    "#         nn.LeakyReLU(inplace=True),\n",
    "#         nn.Dropout1d(p=0.1, inplace=False),\n",
    "#         nn.Conv1d(out_channels, out_channels, kernel_size=3, padding=1, padding_mode='zeros'),\n",
    "#         nn.BatchNorm1d(out_channels),\n",
    "#         nn.LeakyReLU(inplace=True),\n",
    "#         nn.Dropout1d(p=0.1, inplace=False),\n",
    "#     )\n",
    "\n",
    "# class OneHotGenerator(nn.Module):\n",
    "#     def __init__(self, INPUTCHANNELS, OUTPUTCHANNELS, WINDOWSIZE, Down = True, Bottleneck = True):\n",
    "#         super(OneHotGenerator, self).__init__()\n",
    "#         self.WINDOWSIZE = WINDOWSIZE\n",
    "#         self.Down = Down\n",
    "#         self.Bottleneck = Bottleneck\n",
    "#         self.maxpool = nn.MaxPool1d((2))  \n",
    "\n",
    "#         self.down_conv1 = double_conv_pad(INPUTCHANNELS, 32) \n",
    "#         self.down_conv2 = double_conv_pad(32, 64) \n",
    "#         self.down_conv3 = double_conv_pad(64, 128)\n",
    "#         self.down_conv4 = double_conv_pad(128, 256)\n",
    "#         # self.down_conv5 = double_conv_pad(256, 512)\n",
    "#         # self.down_conv6 = double_conv_pad(512, 1024)\n",
    "        \n",
    "#         self.sourcephaseLinear = nn.Linear(6, 1)\n",
    "#         self.sourceinterventionLinear = nn.Linear(11, 1)\n",
    "#         self.sourceFCLinear = nn.Linear(768, 256)\n",
    "\n",
    "#         self.targetphaseLinear = nn.Linear(6, 32)\n",
    "#         self.targetinterventionLinear = nn.Linear(11, 32)\n",
    "#         self.targetFCLinear = nn.Linear(96, 32)\n",
    "\n",
    "#         # self.up_trans1 = nn.ConvTranspose1d(1024, 512, kernel_size=(2), stride=2, padding=0)\n",
    "#         # self.up_conv1 = double_conv_pad(1024, 512)\n",
    "#         # self.up_trans2 = nn.ConvTranspose1d(512, 256, kernel_size=(2), stride=2, padding=0)\n",
    "#         # self.up_conv2 = double_conv_pad(512, 256)\n",
    "#         self.up_trans1 = nn.ConvTranspose1d(256, 128, kernel_size=(2), stride=2, padding=0)\n",
    "#         self.up_conv1 = double_conv_pad(256, 128)\n",
    "#         self.up_trans2 = nn.ConvTranspose1d(128, 64, kernel_size=(2), stride=2, padding=0)\n",
    "#         self.up_conv2 = double_conv_pad(128, 64)\n",
    "#         self.up_trans3 = nn.ConvTranspose1d(64, 32, kernel_size=(2), stride=2, padding=0)\n",
    "#         self.up_conv3 = double_conv_pad(64, 32)\n",
    "\n",
    "#         self.out = nn.Conv1d(32, OUTPUTCHANNELS, kernel_size=1) # kernel_size must be == 1\n",
    "\n",
    "#         self.apply(self._init_weights)\n",
    "        \n",
    "#     def _init_weights(self, module):\n",
    "#         if isinstance(module, nn.Conv1d):\n",
    "#             module.weight.data.normal_(mean=0.0, std=1)\n",
    "#             if module.bias is not None:\n",
    "#                 module.bias.data.zero_()\n",
    "#         elif isinstance(module, nn.ConvTranspose1d):\n",
    "#             module.weight.data.normal_(mean=0.0, std=1)\n",
    "#             if module.bias is not None:\n",
    "#                 module.bias.data.zero_()\n",
    "#         elif isinstance(module, nn.Embedding):\n",
    "#             module.weight.data.normal_(mean=0.0, std=1)\n",
    "#         elif isinstance(module, nn.BatchNorm1d):\n",
    "#             module.weight.data.normal_(mean=0.0, std=1)\n",
    "#             if module.bias is not None:\n",
    "#                 module.bias.data.zero_()\n",
    "#         elif isinstance(module, nn.Linear):\n",
    "#             module.weight.data.normal_(mean=0.0, std=1)\n",
    "#             if module.bias is not None:\n",
    "#                 module.bias.data.zero_()\n",
    "\n",
    "\n",
    "#     def forward(self, input, source_phase, source_intervention, target_phase, target_intervention):\n",
    "#         # downsampling\n",
    "#         if self.Down:\n",
    "#             pS = F.one_hot(source_phase, num_classes=6).type(torch.FloatTensor).to(DEVICE)  #torch.Size([1, 256, 6])\n",
    "#             iS = F.one_hot(source_intervention, num_classes=11).type(torch.FloatTensor).to(DEVICE) #torch.Size([1, 256, 11])\n",
    "#             pS = self.sourcephaseLinear(pS)\n",
    "#             iS = self.sourceinterventionLinear(iS)\n",
    "#             pS = pS.reshape(pS.shape[0], pS.shape[2], pS.shape[1])\n",
    "#             iS = iS.reshape(iS.shape[0], iS.shape[2], iS.shape[1])\n",
    "#             # Fully connected Layers\n",
    "#             # input shape torch.Size([1, 1, 256])\n",
    "#             # reshape pS to torch.Size([1, 256, 1])\n",
    "#             # pS = self.sourcephaseLinear(pS)\n",
    "#             # iS = self.sourceinterventionLinear(iS)\n",
    "#             # pS = pS.reshape(input.shape[0], input.shape[1], input.shape[2]).to(DEVICE)\n",
    "#             # iS = iS.reshape(input.shape[0], input.shape[1], input.shape[2]).to(DEVICE)\n",
    "#             # Concatenate the phase and intervention one hot encodings with the output of the last convolutional layer and reshape\n",
    "#             input = torch.cat([input, pS, iS], 2) # torch.Size([1, 1, 768])\\\n",
    "#             # input = input.reshape(input.shape[0], self.WINDOWSIZE, 96)\n",
    "#             input = self.sourceFCLinear(input).to(DEVICE) \n",
    "\n",
    "#         x1 = self.down_conv1(input)   \n",
    "#         x2 = self.maxpool(x1) \n",
    "#         x3 = self.down_conv2(x2)  \n",
    "#         x4 = self.maxpool(x3) \n",
    "#         x5 = self.down_conv3(x4) \n",
    "#         x6 = self.maxpool(x5) \n",
    "#         x7 = self.down_conv4(x6)     \n",
    "\n",
    "#         # upsampling\n",
    "#         if self.Bottleneck:\n",
    "#             # one hot encoding\n",
    "#             pT = F.one_hot(target_phase, num_classes=6).type(torch.FloatTensor).to(DEVICE)\n",
    "#             iT = F.one_hot(target_intervention, num_classes=11).type(torch.FloatTensor).to(DEVICE)\n",
    "#             # Fully connected Layers\n",
    "#             pT = self.targetphaseLinear(pT).to(DEVICE)\n",
    "#             iT = self.targetinterventionLinear(iT).to(DEVICE)\n",
    "#             # Concatenate the phase and intervention one hot encodings with the output of the last convolutional layer and reshape\n",
    "#             x7 = torch.cat([x7, pT, iT], 1) \n",
    "#             x7 = x7.reshape(x7.shape[0], self.WINDOWSIZE, 96)\n",
    "#             x7 = self.targetFCLinear(x7).to(DEVICE) \n",
    "        \n",
    "#         x = self.up_trans1(x7)\n",
    "#         x = self.up_conv1(torch.cat([x, x5], 1))  # skip connection\n",
    "#         x = self.up_trans2(x)\n",
    "#         x = self.up_conv2(torch.cat([x, x3], 1))  # skip connection\n",
    "#         x = self.up_trans3(x)\n",
    "#         x = self.up_conv3(torch.cat([x, x1], 1))  # skip connection\n",
    "#         x = self.out(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator\n",
    "if ONEHOTENCODING and SKIPCONNECTIONS:\n",
    "    gen_target = OneHotGenerator(INPUTCHANNELS = CHANNELS, OUTPUTCHANNELS = 1, WINDOWSIZE=WINDOW, Down = DOWN, Bottleneck=BOTTLENECK).to(DEVICE)\n",
    "    gen_source = OneHotGenerator(INPUTCHANNELS = 1, OUTPUTCHANNELS = CHANNELS, WINDOWSIZE=WINDOW, Down = DOWN, Bottleneck=BOTTLENECK).to(DEVICE)\n",
    "\n",
    "if not ONEHOTENCODING and SKIPCONNECTIONS:\n",
    "    gen_target = SkipTensorEmbeddingGen(INPUTCHANNELS = CHANNELS, OUTPUTCHANNELS = 1, Down = DOWN, Bottleneck=BOTTLENECK).to(DEVICE)\n",
    "    gen_source = SkipTensorEmbeddingGen(INPUTCHANNELS = 1, OUTPUTCHANNELS = CHANNELS, Down = DOWN, Bottleneck=BOTTLENECK).to(DEVICE)\n",
    "\n",
    "if not ONEHOTENCODING and not SKIPCONNECTIONS:\n",
    "    gen_target = TensorEmbeddingGen(INPUTCHANNELS = CHANNELS, OUTPUTCHANNELS = 1, Down = DOWN, Bottleneck=BOTTLENECK).to(DEVICE)\n",
    "    gen_source = TensorEmbeddingGen(INPUTCHANNELS = 1, OUTPUTCHANNELS = CHANNELS, Down = DOWN, Bottleneck=BOTTLENECK).to(DEVICE)\n",
    "\n",
    "# Discriminator\n",
    "disc_target = MultiChannelDiscriminator(CHANNELS = 1).to(DEVICE)\n",
    "disc_source = MultiChannelDiscriminator(CHANNELS = CHANNELS).to(DEVICE)\n",
    "\n",
    "# Optimizers \n",
    "opt_disc = torch.optim.AdamW(                                         \n",
    "    list(disc_source.parameters()) + list(disc_target.parameters()), \n",
    "    lr=LEARNING_RATE, \n",
    ")\n",
    "opt_gen = torch.optim.AdamW(\n",
    "    list(gen_source.parameters()) + list(gen_target.parameters()),\n",
    "    lr=LEARNING_RATE,\n",
    ")\n",
    "\n",
    "# Scheduler\n",
    "if ReduceLROnPlateau:\n",
    "    gen_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer = opt_gen,\n",
    "                                                           factor=0.1, patience=3, threshold=1e-4,\n",
    "                                                           min_lr=1e-6,\n",
    "                                                    )\n",
    "    disc_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer = opt_disc,\n",
    "                                                            factor=0.1, patience=3, threshold=1e-4,\n",
    "                                                            min_lr=1e-6,\n",
    "                                                    )\n",
    "if MultiStepLR:\n",
    "    gen_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer = opt_gen, milestones=[5,6,7,8], gamma=0.1)\n",
    "                                                        \n",
    "    disc_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer = opt_disc, milestones=[5,6,7,8], gamma=0.1)\n",
    "\n",
    "# losses\n",
    "l1 = nn.L1Loss() \n",
    "mse = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if UNPAIRED and EMBEDDING:\n",
    "    # create dataset with information of the phases and intervention (embedding information)\n",
    "    train_dataset = UnpairedEmbeddingsDataset(df_train, source_signals, target_name = TARGET, window_length = WINDOW)\n",
    "    test_dataset = AnimalDatasetEmbedding(df_test, source_signals, target_name = TARGET, window_length = WINDOW)\n",
    "\n",
    "if not UNPAIRED and EMBEDDING:\n",
    "    train_dataset = AnimalDatasetEmbedding(df_train, source_signals, target_name = TARGET, test = False, window_length = WINDOW)\n",
    "    test_dataset = AnimalDatasetEmbedding(df_test, source_signals, target_name = TARGET, test = True, window_length = WINDOW)\n",
    "\n",
    "\n",
    "# Data loader\n",
    "loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True,)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# start a new wandb run to track this script\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"Cycle_GAN\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"epochs\": NUM_EPOCHS,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_signals(fake_target, fake_source, target, source):\n",
    "    fake_target = fake_target.reshape(-1)\n",
    "    fake_source = fake_source.reshape(-1)\n",
    "    source = source.reshape(-1)\n",
    "    target = target.reshape(-1)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 8))\n",
    "    ax[0].plot(source.cpu().detach().numpy(), label= 'Real source signals')\n",
    "    ax[0].plot(fake_source.cpu().detach().numpy(), label= 'Recreated source signals')\n",
    "    ax[0].set_xlabel('Signal length')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(target.cpu().detach().numpy(), label= 'Real target signal')\n",
    "    ax[1].plot(fake_target.cpu().detach().numpy(), label= 'Recreated target signal')\n",
    "    ax[1].set_xlabel('Signal length')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].legend()\n",
    "\n",
    "def discriminator_loss(disc, reals, fakes):\n",
    "    # calculate how close reals are to being classified as real\n",
    "    real_loss = mse(disc(reals), torch.ones_like(disc(reals)))\n",
    "    # calculate how close fakes are to being classified as fake\n",
    "    fake_loss = mse(disc(fakes), torch.zeros_like(disc(fakes)))\n",
    "    # return the average of real and fake loss\n",
    "    return (real_loss + fake_loss) / 2\n",
    "\n",
    "\n",
    "# @torch.cuda.amp.autocast()\n",
    "def get_disc_loss(source, target, disc_source, disc_target, fake_source, fake_target\n",
    "                    ):\n",
    "    \"\"\"\n",
    "    Return the loss of the discriminator given inputs.\n",
    "    \"\"\"\n",
    "    # generate fakes\n",
    "    # with torch.no_grad():\n",
    "    #     fake_B = gen_B(sig_A, phase, intervention).detach()\n",
    "    #     fake_A = gen_A(sig_B, phase, intervention).detach()\n",
    "    \n",
    "    # discriminator loss\n",
    "    disc_target_loss = discriminator_loss(disc_target, target, fake_target)\n",
    "    disc_source_loss = discriminator_loss(disc_source, source, fake_source)\n",
    "    disc_loss = (disc_source_loss + disc_target_loss) / 2\n",
    "\n",
    "    return disc_loss, disc_source_loss, disc_target_loss\n",
    "\n",
    "# @torch.cuda.amp.autocast()\n",
    "def calc_gen_loss(source, target, source_phase, source_intervention, target_phase, target_intervention,\n",
    "                  gen_source, gen_target, disc_source, disc_target, fake_target, fake_source\n",
    "                  ):\n",
    "    loss = 0\n",
    "\n",
    "    if GAN_LOSS:\n",
    "        g_source_loss = mse(disc_source(fake_source), torch.ones_like(disc_source(fake_source))) \n",
    "        g_target_loss = mse(disc_target(fake_target), torch.ones_like(disc_target(fake_target))) \n",
    "\n",
    "        loss += g_source_loss * LAMBDA_GAN + g_target_loss * LAMBDA_GAN\n",
    "    else:\n",
    "        g_source_loss = torch.tensor(0)\n",
    "        g_target_loss = torch.tensor(0)\n",
    "\n",
    "    if CYCLE:\n",
    "        rec_target = gen_target(fake_source, source_phase, source_intervention, target_phase, target_intervention)\n",
    "        rec_source = gen_source(fake_target, source_phase, source_intervention, target_phase, target_intervention)\n",
    "        cycle_target_loss = l1(target, rec_target)  # l1 loss: Mean absolute error between each element in the input x and target y\n",
    "        cycle_source_loss = l1(source, rec_source)  # l1 loss in cycle GAN paper\n",
    "\n",
    "        loss += cycle_target_loss * LAMBDA_CYCLE + cycle_source_loss * LAMBDA_CYCLE\n",
    "    else:\n",
    "        cycle_target_loss = torch.tensor(0)\n",
    "        cycle_source_loss = torch.tensor(0)\n",
    "\n",
    "    if SUPERVISED:\n",
    "        sup_source_loss = mse(source, fake_source)\n",
    "        sup_target_loss = mse(target, fake_target)\n",
    "\n",
    "        loss += sup_source_loss * LAMBDA_SUPERVISED + sup_target_loss * LAMBDA_SUPERVISED\n",
    "    else:\n",
    "        sup_source_loss = torch.tensor(0)\n",
    "        sup_target_loss = torch.tensor(0)\n",
    "\n",
    "    if IDENTITY:\n",
    "        id_target_loss = l1(target, gen_target(target, source_phase, source_intervention, target_phase, target_intervention))\n",
    "        id_source_loss = l1(source, gen_source(source, source_phase, source_intervention, target_phase, target_intervention))\n",
    "\n",
    "        loss += id_target_loss * LAMBDA_IDENTITY + id_source_loss * LAMBDA_IDENTITY\n",
    "    else:\n",
    "        id_target_loss = torch.tensor(0)\n",
    "        id_source_loss = torch.tensor(0)\n",
    "\n",
    "    return loss, g_source_loss, g_target_loss, cycle_target_loss, cycle_source_loss, id_target_loss, id_source_loss, sup_source_loss, sup_target_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "\n",
    "    for source, target, source_phase, source_intervention, target_phase, target_intervention in loader:\n",
    "        # convert to float16\n",
    "        source = source.float() # neccessary to prevent error: \"Input type (torch.cuda.DoubleTensor) \n",
    "        target = target.float() # and weight type (torch.cuda.HalfTensor) should be the same\"\n",
    "    \n",
    "        # move to GPU\n",
    "        source = source.to(DEVICE)\n",
    "        target = target.to(DEVICE)\n",
    "        source_phase = source_phase.to(DEVICE)\n",
    "        source_intervention = source_intervention.to(DEVICE)\n",
    "        target_phase = target_phase.to(DEVICE)\n",
    "        target_intervention = target_intervention.to(DEVICE)\n",
    "\n",
    "        #  ------------------------------- #\n",
    "        #  ----- train discriminators ---- #\n",
    "        #  ------------------------------- #\n",
    "        with torch.no_grad():\n",
    "            fake_target = gen_target(source, source_phase, source_intervention, target_phase, target_intervention).detach()\n",
    "            fake_source = gen_source(target, source_phase, source_intervention, target_phase, target_intervention).detach()\n",
    "\n",
    "        d_loss, disc_source_loss, disc_target_loss = get_disc_loss(source, target, disc_source, disc_target, fake_source, fake_target)\n",
    "                                                        # source, target, disc_source, disc_target, fake_source, fake_target\n",
    "\n",
    "        # update gradients of discriminator \n",
    "        opt_disc.zero_grad() \n",
    "        d_loss.backward()\n",
    "        opt_disc.step()\n",
    "        # d_scaler.scale(d_loss).backward()  \n",
    "               \n",
    "\n",
    "        # -------------------------------- #\n",
    "        # ------- train generators ------- #\n",
    "        # -------------------------------- # \n",
    "\n",
    "        out = calc_gen_loss(source, target, source_phase, source_intervention, target_phase, target_intervention,\n",
    "                                gen_source, gen_target, disc_source, disc_target, fake_target, fake_source)\n",
    "                            # source, target, source_phase, source_intervention, target_phase, target_intervention,\n",
    "                            # gen_source, gen_target, disc_source, disc_target, fake_target, fake_source\n",
    "\n",
    "        g_loss, g_source_loss, g_target_loss, cycle_target_loss, cycle_source_loss, id_target_loss, id_source_loss, sup_source_loss, sup_target_loss = out\n",
    "        # loss, g_source_loss, g_target_loss, cycle_target_loss, cycle_source_loss, id_target_loss, id_source_loss, sup_source_loss, sup_target_loss\n",
    "\n",
    "        # update gradients of generator\n",
    "        opt_gen.zero_grad()\n",
    "        g_loss.backward()\n",
    "        opt_gen.step()\n",
    "        # g_scaler.scale(g_loss).backward()\n",
    "\n",
    "    # Optimizer step\n",
    "    # d_scaler.step(opt_disc)  \n",
    "    # d_scaler.update()\n",
    "\n",
    "    # g_scaler.step(opt_gen) \n",
    "    # g_scaler.update()\n",
    "\n",
    "    wandb.log({'Train/Discriminator source loss': disc_source_loss.item(),\n",
    "                'Train/Discriminator target loss': disc_target_loss.item(),\n",
    "                'Train/Total Discriminator loss': d_loss.item(),\n",
    "                'Train/Total Generator loss': g_loss.item(),\n",
    "                'Train/Adversarial loss source': g_source_loss.item(),\n",
    "                'Train/Adversarial loss target': g_target_loss.item(),\n",
    "                'Train/Cycle consistency loss source': cycle_source_loss.item(),\n",
    "                'Train/Cycle consistency loss target': cycle_target_loss.item(),\n",
    "                'Train/Supervised loss source': sup_source_loss.item(),\n",
    "                'Train/Supervised loss target': sup_target_loss.item(),\n",
    "                'Learning rate': opt_gen.param_groups[0][\"lr\"],\n",
    "                # 'Train/Identity loss A': id_A_loss.item(),\n",
    "                # 'Train/Identity loss B': id_B_loss.item()\n",
    "                })\n",
    "        \n",
    "\n",
    "    # ------------------------ #\n",
    "    # ------ Validation ------ #\n",
    "    # ------------------------ #\n",
    "\n",
    "    if (epoch+1) % 5 == 0:\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # set models to evaluation mode\n",
    "            disc_source.eval()  # set discriminator to evaluation mode\n",
    "            disc_target.eval()  # turns off Dropouts Layers, BatchNorm Layers etc\n",
    "            gen_target.eval()\n",
    "            gen_source.eval()\n",
    "\n",
    "            for source, target, source_phase, source_intervention, target_phase, target_intervention in test_loader:\n",
    "                # convert to float16\n",
    "                source = source.float()\n",
    "                target = target.float()\n",
    "\n",
    "                # move to GPU\n",
    "                source = source.to(DEVICE)\n",
    "                target = target.to(DEVICE)\n",
    "                source_phase = source_phase.to(DEVICE)\n",
    "                source_intervention = source_intervention.to(DEVICE)\n",
    "                target_phase = target_phase.to(DEVICE)\n",
    "                target_intervention = target_intervention.to(DEVICE)\n",
    "\n",
    "                fake_target = gen_target(source, source_phase, source_intervention, target_phase, target_intervention).detach() # already torch.no_grad()\n",
    "                fake_source = gen_source(target, source_phase, source_intervention, target_phase, target_intervention).detach()\n",
    "\n",
    "                # generate signals during validation\n",
    "                #gen_signals(fake_target, fake_source, target, source)\n",
    "\n",
    "                # calculate l1 loss of fake signals and real signals\n",
    "                test_real_fake_lossB= l1(target, fake_target)   # l1(sig_B, fake_B)\n",
    "                test_real_fake_lossA = l1(source, fake_source)\n",
    "\n",
    "                #  ------------------------------- #\n",
    "                #  ----- test discriminators ----- #\n",
    "                #  ------------------------------- #\n",
    "\n",
    "                test_d_loss, test_disc_A_loss, test_disc_B_loss = get_disc_loss(source, target, disc_source, disc_target, fake_source, fake_target)\n",
    "                \n",
    "                # -------------------------------- #\n",
    "                # ------- test generators -------- #\n",
    "                # -------------------------------- # \n",
    "\n",
    "                out = calc_gen_loss(source, target, source_phase, source_intervention, target_phase, target_intervention,\n",
    "                                gen_source, gen_target, disc_source, disc_target, \n",
    "                                fake_target, fake_source\n",
    "                                )\n",
    "                g_lossT, g_A_lossT, g_B_lossT, cycle_B_lossT, cycle_A_lossT, id_B_lossT, id_A_lossT, sup_A_lossT, sup_B_lossT = out\n",
    "        \n",
    "                # gen_signals(fake_target, fake_source, target, source)\n",
    "\n",
    "            wandb.log({'Test/Generator loss': g_lossT.item(),\n",
    "                        'Test/Discriminator loss': test_d_loss.item(),\n",
    "                        'Test/L1 loss between real signal A and fake signals A': test_real_fake_lossA.item(),\n",
    "                        'Test/L1 loss between real signal B and fake signals B': test_real_fake_lossB.item(),\n",
    "                        'Test/Discriminator A loss': test_disc_A_loss.item(),\n",
    "                        'Test/Discriminator B loss': test_disc_B_loss.item(),\n",
    "                        'Test/Adversarial or GAN loss A': g_A_lossT.item(),\n",
    "                        'Test/Adversarial or GAN loss B': g_B_lossT.item(),\n",
    "                        'Test/Cycle consistency loss A': cycle_A_lossT.item(),\n",
    "                        'Test/Cycle consistency loss B': cycle_B_lossT.item(),\n",
    "                        'Test/Supervised loss A': sup_A_lossT.item(),\n",
    "                        'Test/Supervised loss B': sup_B_lossT.item(),\n",
    "                        'Test/Epoch': epoch+1,\n",
    "                })\n",
    "            \n",
    "            \n",
    "      \n",
    "    disc_scheduler.step(d_loss)\n",
    "    gen_scheduler.step(g_loss)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get losses of the training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_losses = []\n",
    "target_losses = []\n",
    "for source, target, source_phase, source_intervention, target_phase, target_intervention in test_loader:                \n",
    "                    \n",
    "    source = source.float()\n",
    "    target = target.float()\n",
    "    source = source.to(DEVICE)\n",
    "    target = target.to(DEVICE)\n",
    "    source_phase = source_phase.to(DEVICE)\n",
    "    source_intervention = source_intervention.to(DEVICE)\n",
    "    target_phase = target_phase.to(DEVICE)\n",
    "    target_intervention = target_intervention.to(DEVICE)\n",
    "\n",
    "    fake_target = gen_target(source, source_phase, source_intervention, target_phase, target_intervention)\n",
    "    fake_source = gen_source(target, source_phase, source_intervention, target_phase, target_intervention)\n",
    "    l1_source = l1(source, fake_source)\n",
    "    l1_target = l1(target, fake_target)\n",
    "    source_losses.append(l1_source.item())\n",
    "    target_losses.append(l1_target.item())\n",
    "\n",
    "print(f\"Average L1 loss of source signals: {np.mean(source_losses)}\")\n",
    "print(f\"Average L1 loss of target signals: {np.mean(target_losses)}\")\n",
    "\n",
    "# get min and max of losses\n",
    "min_max_loss_source = np.min(source_losses), np.max(source_losses)\n",
    "min_max_loss_target = np.min(target_losses), np.max(target_losses)\n",
    "print(f\"Min and max loss of source signals: {min_max_loss_source}\")\n",
    "print(f\"Min and max loss of target signals: {min_max_loss_target}\")\n",
    "\n",
    "# get median of losses\n",
    "median_loss_source = np.median(source_losses)\n",
    "median_loss_target = np.median(target_losses)\n",
    "print(f\"Median loss of source signals: {median_loss_source}\")\n",
    "print(f\"Median loss of target signals: {median_loss_target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate signals\n",
    "idx = 0             \n",
    "phases = df['Phasenzuordnung'].unique()\n",
    "for source, target, source_phase, source_intervention, target_phase, target_intervention in test_loader:\n",
    "    if idx == 5:\n",
    "        break                 \n",
    "                    \n",
    "    source = source.float()\n",
    "    target = target.float()\n",
    "    source = source.to(DEVICE)\n",
    "    target = target.to(DEVICE)\n",
    "    source_phase = source_phase.to(DEVICE)\n",
    "    source_intervention = source_intervention.to(DEVICE)\n",
    "    target_phase = target_phase.to(DEVICE)\n",
    "    target_intervention = target_intervention.to(DEVICE)\n",
    "\n",
    "    fake_target = gen_target(source, source_phase, source_intervention, target_phase, target_intervention)\n",
    "    fake_source = gen_source(target, source_phase, source_intervention, target_phase, target_intervention)\n",
    "\n",
    "                        \n",
    "    fake_target = fake_target.reshape(-1)\n",
    "    fake_source = fake_source.reshape(-1)\n",
    "    source = source.reshape(-1)\n",
    "    target = target.reshape(-1)\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 8))\n",
    "    ax[0].plot(source.cpu().detach().numpy(), label= 'Real source signals')\n",
    "    ax[0].plot(fake_source.cpu().detach().numpy(), label= 'Recreated source signals')\n",
    "    ax[0].set_xlabel('Signal length')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend()\n",
    "\n",
    "    ax[1].plot(target.cpu().detach().numpy(), label= 'Real target signal')\n",
    "    ax[1].plot(fake_target.cpu().detach().numpy(), label= 'Recreated target signal')\n",
    "    ax[1].set_xlabel('Signal length')\n",
    "    ax[1].set_ylabel('Loss')\n",
    "    ax[1].legend()\n",
    "\n",
    "    idx += 1       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "9de897a1f02868636d0ac53130d687147b532c1438896437dda8e287739e6223"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
